{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and packages\n",
    "import pandas as pd, numpy as np\n",
    "import json\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import scispacy, spacy\n",
    "nlp = spacy.load('en_core_sci_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 29315\n"
     ]
    }
   ],
   "source": [
    "fileDirectory1 = '/home/rahul/DeepBlue/Projects/CORD-19/noncomm_use_subset/noncomm_use_subset'\n",
    "fileDirectory2 = '/home/rahul/DeepBlue/Projects/CORD-19/comm_use_subset/comm_use_subset'\n",
    "fileDirectory3 = '/home/rahul/DeepBlue/Projects/CORD-19/biorxiv_medrxiv/biorxiv_medrxiv'\n",
    "fileDirectory4 = '/home/rahul/DeepBlue/Projects/CORD-19/custom_license/custom_license'\n",
    "jsonFiles1 = [join(fileDirectory1,f) for f in listdir(fileDirectory1) if isfile(join(fileDirectory1,f))]\n",
    "jsonFiles2 = [join(fileDirectory2,f) for f in listdir(fileDirectory2) if isfile(join(fileDirectory2,f))]\n",
    "jsonFiles3 = [join(fileDirectory3,f) for f in listdir(fileDirectory3) if isfile(join(fileDirectory3,f))]\n",
    "jsonFiles4 = [join(fileDirectory4,f) for f in listdir(fileDirectory4) if isfile(join(fileDirectory4,f))]\n",
    "jsonFiles = jsonFiles1+jsonFiles2+jsonFiles3+jsonFiles4\n",
    "print(f'Number of files: {len(jsonFiles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7649d01af3224904969a24dc467ae1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29315.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "dictList = []\n",
    "for f in tqdm(jsonFiles):\n",
    "    with open(f) as currFile:\n",
    "        data = json.load(currFile)\n",
    "    dictList.append(data)\n",
    "df = pd.DataFrame(dictList)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for i in range(len(df)):\n",
    "    titles.append(df.metadata[i]['title'])\n",
    "df2 = pd.DataFrame()\n",
    "df2['paper_id'] = df['paper_id']\n",
    "df2['title'] = titles\n",
    "df2.to_csv('PaperID_Title.csv', index=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'first': 'Luke',\n",
       "  'middle': ['D'],\n",
       "  'last': 'Knibbs',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': 'International Laboratory for Air Quality and Health',\n",
       "   'institution': 'Queensland University of Technology',\n",
       "   'location': {'settlement': 'Brisbane',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Graham',\n",
       "  'middle': ['R'],\n",
       "  'last': 'Johnson',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': 'International Laboratory for Air Quality and Health',\n",
       "   'institution': 'Queensland University of Technology',\n",
       "   'location': {'settlement': 'Brisbane',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Timothy',\n",
       "  'middle': ['J'],\n",
       "  'last': 'Kidd',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Joyce',\n",
       "  'middle': [],\n",
       "  'last': 'Cheney',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Keith',\n",
       "  'middle': [],\n",
       "  'last': 'Grimwood',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Jacqueline',\n",
       "  'middle': ['A'],\n",
       "  'last': 'Kattenbelt',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Peter',\n",
       "  'middle': ['K'],\n",
       "  'last': 'O&apos;rourke',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': 'QIMR/RBWH Statistics Unit',\n",
       "   'institution': 'QIMR Berghofer Medical Research Institute',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Kay',\n",
       "  'middle': ['A'],\n",
       "  'last': 'Ramsay',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Peter',\n",
       "  'middle': ['D'],\n",
       "  'last': 'Sly',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Claire',\n",
       "  'middle': ['E'],\n",
       "  'last': 'Wainwright',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Michelle',\n",
       "  'middle': ['E'],\n",
       "  'last': 'Wood',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The Prince Charles Hospital',\n",
       "   'location': {'addrLine': 'The Prince Charles Hospital, Rode Road',\n",
       "    'postCode': '4032',\n",
       "    'settlement': 'Chermside, Chermside',\n",
       "    'region': 'Queensland, Queensland',\n",
       "    'country': 'Australia, Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Lidia',\n",
       "  'middle': [],\n",
       "  'last': 'Morawska',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': 'International Laboratory for Air Quality and Health',\n",
       "   'institution': 'Queensland University of Technology',\n",
       "   'location': {'settlement': 'Brisbane',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Scott',\n",
       "  'middle': ['C'],\n",
       "  'last': 'Bell',\n",
       "  'suffix': '',\n",
       "  'affiliation': {'laboratory': '',\n",
       "   'institution': 'The University of Queensland',\n",
       "   'location': {'settlement': 'Herston',\n",
       "    'region': 'Queensland',\n",
       "    'country': 'Australia'}},\n",
       "  'email': ''},\n",
       " {'first': 'Scott',\n",
       "  'middle': [],\n",
       "  'last': 'Bell@health',\n",
       "  'suffix': '',\n",
       "  'affiliation': {},\n",
       "  'email': ''},\n",
       " {'first': '',\n",
       "  'middle': [],\n",
       "  'last': 'Qld',\n",
       "  'suffix': '',\n",
       "  'affiliation': {},\n",
       "  'email': ''},\n",
       " {'first': '',\n",
       "  'middle': [],\n",
       "  'last': 'Gov',\n",
       "  'suffix': '',\n",
       "  'affiliation': {},\n",
       "  'email': ''},\n",
       " {'first': '',\n",
       "  'middle': [],\n",
       "  'last': 'Au',\n",
       "  'suffix': '',\n",
       "  'affiliation': {},\n",
       "  'email': ''}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metadata[0]['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemovePunctuation(text):\n",
    "#    import string\n",
    "#    table = str.maketrans(\"\",\"\", string.punctuation)\n",
    "#    return text.translate(table)\n",
    "    text = text.replace('-',' ')\n",
    "    return_text = [c for c in text if (c.isalpha() or c==' ')]\n",
    "    return_text = ''.join(return_text)\n",
    "    return return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaabgs\n"
     ]
    }
   ],
   "source": [
    "print(RemovePunctuation('aaa.bg!s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveCitationsFromParagraph(df, doc_id, para_id):\n",
    "    remove_indices = []\n",
    "    for i in range(len(df['body_text'][doc_id][para_id]['cite_spans'])):\n",
    "        curr_start = df['body_text'][doc_id][para_id]['cite_spans'][i]['start']\n",
    "        curr_end = df['body_text'][doc_id][para_id]['cite_spans'][i]['end']\n",
    "        for k in range(curr_start,curr_end):\n",
    "            remove_indices.append(k)\n",
    "    remove_indices = set(remove_indices)\n",
    "    text_return = ''.join([char for idx,char in enumerate(df['body_text'][doc_id][para_id]['text'])\n",
    "                           if idx not in remove_indices]) \n",
    "    return text_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPaperAuthors(df, doc_id):\n",
    "    try:\n",
    "        authors = df.metadata[doc_id]['authors'][0]['last']\n",
    "        for i in range(1,len(df.metadata[doc_id]['authors'])):\n",
    "            authors = authors + ', ' + df.metadata[doc_id]['authors'][i]['last']\n",
    "    except:\n",
    "        authors='NA'\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToLemma(text):\n",
    "    doc = nlp(text)\n",
    "    return [word.lemma_ for word in doc if not(word.like_num or word.is_stop or word.is_punct or word.is_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b393caf6ec4d4f92b42ffac55e4ad45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11471.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>txt</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df1b6713549bcbe22ec020aaf62275280f096b9a</td>\n",
       "      <td>Viability of Pseudomonas aeruginosa in cough a...</td>\n",
       "      <td>communicable respiratory infections are an imp...</td>\n",
       "      <td>Knibbs, Johnson, Kidd, Cheney, Grimwood, Katte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84a328211fa0a65959af45f0e55e52961c00005f</td>\n",
       "      <td>Oxidized LDL upregulates macrophage DPP4 expre...</td>\n",
       "      <td>dipeptidyl peptidase iv dpp is a single pass t...</td>\n",
       "      <td>Rao, Zhao, Braunstein, Mao, Razavi, Duan, Wei,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>817a885e9613363e08ef920a9e5826a4cb9e1c1e</td>\n",
       "      <td>CLINICAL EXPERIMENTAL VACCINE RESEARCH</td>\n",
       "      <td>virulent ndv the causative agent of newcastle ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3de90c8c18dbed90408c4a5cc5cb94f856c9f637</td>\n",
       "      <td></td>\n",
       "      <td>in humans cyclosporiasis and cystoisosporiasis...</td>\n",
       "      <td>Lee, Kim, Cheon, Moon, Seo, Jung, Shin, Choi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14e878a6400d8320e2c781a76edc4a14f4cec1df</td>\n",
       "      <td>Viral etiology of acute respiratory infections...</td>\n",
       "      <td>introduction acute respiratory tract infection...</td>\n",
       "      <td>Masoud, Hanna-Wakim, Zaraket, Araj, Matar, Dbaibo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doc_id  \\\n",
       "0  df1b6713549bcbe22ec020aaf62275280f096b9a   \n",
       "1  84a328211fa0a65959af45f0e55e52961c00005f   \n",
       "2  817a885e9613363e08ef920a9e5826a4cb9e1c1e   \n",
       "3  3de90c8c18dbed90408c4a5cc5cb94f856c9f637   \n",
       "4  14e878a6400d8320e2c781a76edc4a14f4cec1df   \n",
       "\n",
       "                                               title  \\\n",
       "0  Viability of Pseudomonas aeruginosa in cough a...   \n",
       "1  Oxidized LDL upregulates macrophage DPP4 expre...   \n",
       "2             CLINICAL EXPERIMENTAL VACCINE RESEARCH   \n",
       "3                                                      \n",
       "4  Viral etiology of acute respiratory infections...   \n",
       "\n",
       "                                                 txt  \\\n",
       "0  communicable respiratory infections are an imp...   \n",
       "1  dipeptidyl peptidase iv dpp is a single pass t...   \n",
       "2  virulent ndv the causative agent of newcastle ...   \n",
       "3  in humans cyclosporiasis and cystoisosporiasis...   \n",
       "4  introduction acute respiratory tract infection...   \n",
       "\n",
       "                                              author  \n",
       "0  Knibbs, Johnson, Kidd, Cheney, Grimwood, Katte...  \n",
       "1  Rao, Zhao, Braunstein, Mao, Razavi, Duan, Wei,...  \n",
       "2                                                 NA  \n",
       "3       Lee, Kim, Cheon, Moon, Seo, Jung, Shin, Choi  \n",
       "4  Masoud, Hanna-Wakim, Zaraket, Araj, Matar, Dbaibo  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "doc_id = []\n",
    "doc_title = []\n",
    "doc_txt = []\n",
    "doc_authors = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    doc_id.append(df.paper_id[i])\n",
    "    doc_title.append(df.metadata[i]['title'])\n",
    "    doc_authors.append(GetPaperAuthors(df,i))\n",
    "    temp = []\n",
    "    for k in range(len(df['body_text'][i])):\n",
    "        curr_para = RemoveCitationsFromParagraph(df,i,k)\n",
    "        temp.append(curr_para)\n",
    "    curr_txt = ' '.join(temp) # This text has no citations in it\n",
    "    curr_txt = re.sub(r'http\\S+', '', curr_txt) # This text has no websites in it\n",
    "    curr_txt = RemovePunctuation(curr_txt) # This text has no punctuation in it\n",
    "    curr_txt = curr_txt.lower() # This text is all in lower case\n",
    "    #curr_txt = ConvertToLemma(curr_txt) # This text has word lemmas instead of full words\n",
    "    doc_txt.append(curr_txt)\n",
    "df2 = pd.DataFrame()\n",
    "df2['doc_id'] = doc_id\n",
    "df2['title'] = doc_title\n",
    "df2['txt'] = doc_txt\n",
    "df2['author'] = doc_authors\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea53a99520d340e1a3c5891917f766f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11471.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a lemma column where all words are lemmatised\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Increase max length of document NLP will look at\n",
    "nlp.max_length = 1e7\n",
    "unique_lemmas = []\n",
    "lemmas = []\n",
    "for i in tqdm(range(min(1000,len(df2)))):\n",
    "    doc = nlp(df2.txt[i])\n",
    "    if(len(doc)>nlp.max_length): # Clip documents to max length\n",
    "        doc = doc[0:nlp.max_length]\n",
    "    doclemma = []\n",
    "    uniquedoclemma = []\n",
    "    for token in doc:\n",
    "        doclemma.append(token.lemma_)\n",
    "        if(token.lemma_ not in uniquedoclemma):\n",
    "            uniquedoclemma.append(token.lemma_)\n",
    "    lemmas.append(doclemma)\n",
    "    unique_lemmas.append(uniquedoclemma)\n",
    "df2['lemmas'] = lemmas\n",
    "df2['unique_lemmas'] = unique_lemmas\n",
    "df2.to_pickle(\"DFWithLemmas_part1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lemma column where all words are lemmatised\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Increase max length of document NLP will look at\n",
    "nlp.max_length = 1e7\n",
    "lemmas = []\n",
    "for i in tqdm(range(len(df2))):\n",
    "    doc = nlp(df2.txt[i])\n",
    "    if(len(doc)>nlp.max_length): # Clip documents to max length\n",
    "        doc = doc[0:nlp.max_length]\n",
    "    doclemma = []\n",
    "    for token in doc:\n",
    "        doclemma.append(token.lemma_)\n",
    "    lemmas.append(doclemma)\n",
    "df2['nonunique_lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
